version: '2'

services:
  kafka_monitor:
    image: istresearch/scrapy-cluster:kafka-monitor-ci-dev
    container_name: kafka-monitor
    build:
      context: .
      dockerfile: docker/kafka-monitor/Dockerfile.py3
    depends_on:
      - kafka
      - redis
    restart: always
  redis_monitor:
    image: istresearch/scrapy-cluster:redis-monitor-ci-dev
    container_name: redis-monitor
    build:
      context: .
      dockerfile: docker/redis-monitor/Dockerfile.py3
    depends_on:
      - kafka
      - redis
      - zookeeper
    restart: always
  crawler:
    image: istresearch/scrapy-cluster:crawler-ci-dev
    container_name: crawler
    build:
      context: .
      dockerfile: docker/crawler/Dockerfile.py3
    depends_on:
      - kafka
      - redis
      - zookeeper
    restart: always
  rest:
    image: istresearch/scrapy-cluster:rest-ci-dev
    container_name: rest
    build:
      context: .
      dockerfile: docker/rest/Dockerfile.py3
    depends_on:
      - kafka
      - redis
    restart: always
    ports:
      - "5343:5343"
  ui:
    image: istresearch/scrapy-cluster:ui-ci-dev
    container_name: ui
    build:
      context: .
      dockerfile: docker/ui/Dockerfile.py3
    depends_on:
      - kafka
      - redis
    restart: always
    ports:
      - "5000:5000"
#  redis:
#    image: redis
#    container_name: redis
#    # command: redis-server --requirepass redispassword
#    ports:
#      - "6379:6379"
#    restart: always
  zookeeper:
    image: confluentinc/cp-zookeeper:7.1.2
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - 32181:2181
  kafka:
    image: confluentinc/cp-kafka:7.1.2
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "testTopic:1:1"
    depends_on:
      - zookeeper
    restart: always

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    restart: always
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
#      KAFKA_CLUSTERS_0_JMXPORT: 9997
#      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schemaregistry0:8085
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: first
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
  mysql-db:
    image: mysql:5.7
    container_name: mysql
    restart: always
    platform: linux/amd64
    environment:
      MYSQL_DATABASE: 'db'
      MYSQL_USER: 'usr'
      MYSQL_PASSWORD: 'rootpass'
      MYSQL_ROOT_PASSWORD: 'rootpass'
    ports:
      - '3306:3306'
    expose:
      - '3306'
    volumes:
      - ./scripts:/docker-entrypoint-initdb.d
      - ${SQL_DB_DATA_PATH}:/var/lib/mysql
  mongo:
    image: mongo
    container_name: mongo
    environment:
      - MONGO_INITDB_ROOT_USERNAME=devroot
      - MONGO_INITDB_ROOT_PASSWORD=devroot
      - MONGO_INITDB_DATABASE=int-parser
    volumes:
      - .mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
      - ~/apps/int-data:/data/db
    ports:
      - 27017:27017
      - 9229:9229
  splash:
    image: scrapinghub/splash:latest
    container_name: splash
    ports:
      - "8050:8050"
  redis:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    command: redis-server --save 20 1 --loglevel debug
    volumes:
      - cache:/data
volumes:
  cache:
    driver: local